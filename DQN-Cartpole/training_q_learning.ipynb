{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "training_q_learning.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "ZFW05dxqY7nU",
    "9m4PEscghHug",
    "uHRj7pVIY7nb",
    "IvqltimhY7nh",
    "fT8o7oXAY7ni"
   ]
  },
  "kernelspec": {
   "name": "dsqnvenv",
   "language": "python",
   "display_name": "DSQNvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuWLQT-1Y7nC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DQN vs. DSQN for the CartPole Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oipXcfdsJ-L",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ewRHcGuKgQkq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "basis_dir = './results/'"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "metadata": {
    "id": "QWPneI_nsEOx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "outputs": [],
=======
   "metadata": {
    "id": "n-N3ySIiY7nM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "#@title Imports{ form-width: \"20%\", display-mode: \"form\" }\n",
    "import os\n",
    "import gym\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import importlib\n",
    "import json\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "from agent import Agent, ReplayBuffer\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from textwrap import wrap\n",
    "\n",
    "\n",
    "#%matplotlib inline"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
=======
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hptOh61RuVQX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f8e36211-6284-48e4-b653-aee156696e95",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "experiment_type = [\"default\",\"twoneuron\", \"ttfs\",\"poisson\" , \"fre\"]\n",
    "type_nr = 0\n",
    "\n",
    "from model import QNetwork, DSNN\n",
    "print(\"Imported {} model\".format(experiment_type[type_nr]))"
   ],
>>>>>>> local_updates
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported default model\n"
     ]
    }
   ],
   "source": [
    "experiment_type = [\"default\",\"twoneuron\", \"ttfs\",\"poisson\" , \"fre\"]\n",
    "type_nr = 0\n",
    "\n",
    "from model import QNetwork, DSNN\n",
    "print(\"Imported {} model\".format(experiment_type[type_nr]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "outputs": [],
=======
   "metadata": {
    "id": "Cy_5z_yLY7nO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Environment specific parameters\n",
    "env_name = 'CartPole-v0'\n",
    "n_runs = 5\n",
    "n_evaluations = 100\n",
    "max_steps = 200\n",
    "num_episodes = 1000\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['result_32_ttfs_2022622', 'result_12_poisson_2022324', 'result_8_poisson_2022322_pop', 'result_11_poisson_2022322', 'result_21_fre_2022411', 'result_25_poisson_2022426', 'result_14_poisson_2022328', 'result_9_poisson_2022124', 'result_10_poisson_2022322', 'result_1_poisson_20211215', 'result_13_fre_2022324', 'result_11_poisson_2022125', 'decent_ttfs_2', 'result_31_ttfs_2022518', 'result_21_poisson_2022412', 'result_10_poisson_2022124', 'result_15_poisson_2022329', 'result_24_poisson_2022412', 'decent_ttfs_5', 'result_29_poisson_2022514', 'result_20_poisson_2022411', 'result_18_fre_2022411', 'result_30_ttfs_2022516', 'result_7_poisson_202231', 'result_30_ttfs_2022515', 'result_23_poisson_2022412', 'result_9_poisson_2022322', 'result_4_poisson_202213', 'result_27_poisson_2022427', 'result_28_poisson_2022514', 'result_6_ttfs_2022119', 'result_16_poisson_2022329', 'result_17_fre_202247', 'result_22_poisson_2022412']\n",
      "Created Directory ./results/result_33_default_202272 to store the results in\n"
     ]
    }
   ],
=======
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGX9mUehY7nP",
    "outputId": "a0eab86c-277d-4c9c-9437-c22fc92dc2ed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Create Results Directory\n",
    "\n",
    "dirs = os.listdir(basis_dir)\n",
    "print(dirs)\n",
    "if not any('result' in d for d in dirs):\n",
    "    result_id = 1\n",
    "else:\n",
    "    results = [d for d in dirs if 'result' in d]\n",
    "    result_id = len(results) + 1\n",
    "\n",
    "# Get today's date and add it to the results directory\n",
    "d = date.today()\n",
    "result_dir = basis_dir  +'result_'+ str(result_id) + '_' + experiment_type[type_nr] + '_{}'.format(\n",
    "    str(d.year) + str(d.month) + str(d.day))\n",
    "os.mkdir(result_dir)\n",
    "print('Created Directory {} to store the results in'.format(result_dir))\n"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
=======
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['result_32_ttfs_2022622', 'result_12_poisson_2022324', 'result_8_poisson_2022322_pop', 'result_11_poisson_2022322', 'result_21_fre_2022411', 'result_41_default_202275', 'result_25_poisson_2022426', 'result_14_poisson_2022328', 'result_9_poisson_2022124', 'result_10_poisson_2022322', 'result_37_poisson_202273', 'result_1_poisson_20211215', 'result_13_fre_2022324', 'result_11_poisson_2022125', 'result_35_default_202273', 'decent_ttfs_2', 'result_31_ttfs_2022518', 'result_21_poisson_2022412', 'result_40_default_202275', 'result_43_ttfs_202278', 'result_10_poisson_2022124', 'result_15_poisson_2022329', 'result_24_poisson_2022412', 'result_39_poisson_202273', 'decent_ttfs_5', 'result_29_poisson_2022514', 'result_20_poisson_2022411', 'result_18_fre_2022411', 'result_34_default_202272', 'result_30_ttfs_2022516', 'result_33_default_202272', 'result_44_ttfs_202278', 'result_42_default_202277', 'result_7_poisson_202231', 'result_30_ttfs_2022515', 'result_23_poisson_2022412', 'result_38_poisson_202273', 'result_9_poisson_2022322', 'result_36_default_202273', 'result_45_default_202278', 'result_4_poisson_202213', 'result_27_poisson_2022427', 'result_28_poisson_2022514', 'result_6_ttfs_2022119', 'result_16_poisson_2022329', 'result_17_fre_202247', 'result_22_poisson_2022412']\n",
      "Created Directory ./results/result_46_default_202279 to store the results in\n"
     ]
>>>>>>> local_updates
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "outputs": [],
=======
   "metadata": {
    "id": "92OumBHMc1Io",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "#@title Change Result Directory { form-width: \"20%\", display-mode: \"form\" }\n",
    "#result_dir = 'result_12_20211028'"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
=======
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xbsSYOATY7nR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "#@title Hyperparameters { form-width: \"20%\", display-mode: \"form\" }\n",
    "batch_size = 1\n",
    "discount_factor = 0.999\n",
    "eps_start = 1.0\n",
    "eps_end = 0.05\n",
    "eps_decay = 0.999\n",
    "update_every = 4\n",
    "target_update_frequency = 100\n",
    "learning_rate = 0.003\n",
    "replay_memory_size = 4*10**4\n",
    "tau = 1e-3"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
=======
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fqz8TdGUY7nS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "#@title SNN Hyperparameters { form-width: \"20%\", display-mode: \"form\" }\n",
    "time_step = 1e-3 # 1ms\n",
    "simulation_time = 10\n",
    "weight_scale = 1\n",
<<<<<<< HEAD
    "threshold = 0.1\n",
=======
    "threshold = 0.3\n",
>>>>>>> local_updates
    "architecture = [4, 64, 64, 2]\n",
    "\n",
    "# Tau\n",
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "alpha = 0.1\n",
    "beta = 0.8\n",
    "\n",
    "#Calculated values, as can be found in XXXXXX\n",
    "#alpha   = float(np.exp(-time_step/tau_syn))\n",
    "#beta    = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "two_neuron=False\n",
    "population_coding=False\n",
    "population_size = 3"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
=======
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AqNxA0mQY7nT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "seeds = [random.getrandbits(32) for _ in range(n_runs)]\n",
    "np.save(result_dir + '/' + 'seeds', seeds)\n",
    "#seeds = np.load(basis_dir + 'seeds.npy').tolist()"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
=======
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cDQEvJkOkme8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "#@title Useful Functions { form-width: \"20%\", display-mode: \"form\" }\n",
    "def loadScores(score_dir, score_name, amount):\n",
    "    score_list = []\n",
    "    for i in range(amount):\n",
    "      score_list.append(np.load(score_dir + '/' + score_name + '_{}'.format(i) + '.npy'))\n",
    "    return score_list\n",
    "\n",
    "def create_params_dict():\n",
    "    params = {}\n",
    "    params.update( {'alpha' : alpha} )\n",
    "    params.update( {'beta' : beta} )\n",
    "    params.update( {'threshold' : threshold} )\n",
    "    params.update( {'batch_size' : batch_size} )\n",
    "    params.update( {'discount_factor' : discount_factor} )\n",
    "    params.update( {'eps_start' : eps_start} )\n",
    "    params.update( {'eps_end' : eps_end} )\n",
    "    params.update( {'eps_decay' : eps_decay} )\n",
    "    params.update( {'update_every' : update_every} )\n",
    "    params.update( {'target_update_frequency' : target_update_frequency} )\n",
    "    params.update( {'learning_rate' : learning_rate} )\n",
    "    params.update( {'replay_memory_size' : replay_memory_size} )\n",
    "\n",
    "    params.update( {'tau' : tau} )\n",
    "    params.update( {'time_step' : time_step} )\n",
    "    params.update( {'simulation_time' : simulation_time} )\n",
    "\n",
    "    params.update( {'weight_scale' : weight_scale} )\n",
    "    params.update( {'architecture' : architecture} )\n",
    "    params.update( {'seeds' : seeds} )\n",
    "\n",
    "    params.update( {'population_coding' : population_coding} )\n",
    "    params.update( {'population_size' : population_size} )\n",
    "    params.update( {'two_neuron' : two_neuron} )\n",
    "    return params\n",
    "\n",
    "def saveHyperparametersToFile():\n",
    "    params = create_params_dict()\n",
    "\n",
    "    # Serialize data into file:\n",
    "    json.dump( params, open( result_dir +\"/hyperparameters.json\", 'w' ) )\n",
    "\n",
    "def getDateTime():\n",
    "  return datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")  \n",
    "\n",
    "# Plot scores of individual runs\n",
    "def plot_score(smoothed_score,i, params = None):\n",
    "    plt.clf()\n",
    "    if params:\n",
    "        param_title = str(params)\n",
    "        plt.title('\\n'.join(wrap(param_title,60)), fontsize=8)\n",
    "    plt.plot(smoothed_score)\n",
    "    plt.ylim(0, 250)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(result_dir + '/training_dsqn_{}.png'.format(i), dpi=1000)\n",
    "    #plt.show()\n",
    "\n",
    "def init_scaler(two_neuron = False):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    if two_neuron:\n",
    "        scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "    if env_name == 'MountainCar-v0':\n",
    "        limits = np.asarray([[-1.2, -0.07],\n",
    "                          [0.6, 0.07]])\n",
    "    else:\n",
    "        #[position of cart, velocity of cart, angle of pole, rotation rate of pole]\n",
    "        limits = np.asarray([[-4.8, -3, -0.21 , -3],\n",
    "                          [4.8, 3 , 0.21, 3]])\n",
    "\n",
    "    # fit data\n",
    "    scaler.fit(limits)\n",
    "    return scaler"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
=======
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2lIdw3XhSTI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFW05dxqY7nU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DQN Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Kau_vuPY7nV",
    "scrolled": false,
    "outputId": "8952da70-7e9a-4a3b-93a9-8bc11c05676e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# DSQN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
=======
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xE_9tivgY7nW",
    "scrolled": true,
    "outputId": "6dbc44e7-c2b4-4124-b039-afb96e1dcebc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "## DSQN Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "wy66b27uEb8d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "best_runs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "tXn_qeXDY7nY",
    "outputId": "a2607d29-38d5-4d81-fedb-c08b6764f28c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Enables the python console on exeption\n",
    "%pdb off"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
=======
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1oA-1tRhCOu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DSQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEEV7qefjKKb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DSQN Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmdnlMAAge-i",
    "outputId": "98fd32c5-d753-41b7-fcd2-5e94db0a664b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "type_nr = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIMVWMGnejfZ",
    "outputId": "01b1c0e4-dca7-4208-c1d0-2ada4667c57d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "#@title Reload changed model file { form-width: \"20%\", display-mode: \"form\" }\n",
    "model_string = \"default\"\n",
    "if experiment_type[type_nr] == \"twoneuron\":\n",
    "    model_string = \"twoneuron\"\n",
    "    import model_twoneurons\n",
    "    importlib.reload(model_twoneurons)\n",
    "    from model_twoneurons import QNetwork, DSNN\n",
    "elif experiment_type[type_nr] == \"poisson\":\n",
    "    model_string = \"poisson\"\n",
    "    import model_poisson\n",
    "    importlib.reload(model_poisson)\n",
    "    from model_poisson import QNetwork, DSNN\n",
    "elif experiment_type[type_nr] == \"ttfs\":\n",
    "    model_string = \"ttfs\"\n",
    "    import model_ttfs\n",
    "    importlib.reload(model_ttfs)\n",
    "    from model_ttfs import QNetwork, DSNN\n",
    "elif experiment_type[type_nr] == \"fre\":\n",
    "    model_string = \"fre\"\n",
    "    import model_fre\n",
    "    importlib.reload(model_fre)\n",
    "    from model_fre import QNetwork, DSNN\n",
    "else :\n",
    "    import model\n",
    "    importlib.reload(model)\n",
    "    from model import QNetwork, DSNN\n",
    "print(\"Reloaded {} model\".format(model_string))"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
=======
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded default model\n"
     ]
>>>>>>> local_updates
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "lyPTZkdbewCB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "#@title Reload changed agent file { form-width: \"20%\", display-mode: \"form\" }\n",
    "\n",
    "import agent\n",
    "importlib.reload(agent)\n",
    "from agent import Agent, ReplayBuffer"
   ],
<<<<<<< HEAD
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import agent_tr\n",
    "importlib.reload(agent_tr)\n",
    "from agent_tr import Agent, ReplayBuffer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
=======
   "execution_count": 14,
   "outputs": []
  },
  {
>>>>>>> local_updates
   "cell_type": "markdown",
   "source": [
    "## DSQN Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "source": [
    "DSQNs with two-neurons-input encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run # 0 at 09/07/2022 18:38:08\n",
      "Episode 100\tAverage Score: 44.51\t Epsilon: 0.05\n",
      "Episode 146\tAverage Score: 96.50\t Epsilon: 0.05\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_27044/1169840304.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     23\u001B[0m                   num_episodes, max_steps, i_run, result_dir, seed, tau, SQN=True, quantization=False)\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m     \u001B[0msmoothed_scores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbest_average_after\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_agent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult_dir\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'/scores_{}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi_run\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Private/Uni/MA/Code/dsqn_openaigym/DQN-Cartpole/agent.py\u001B[0m in \u001B[0;36mtrain_agent\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    247\u001B[0m                 \u001B[0maction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect_action\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    248\u001B[0m                 \u001B[0mnext_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 249\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnext_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    250\u001B[0m                 \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    251\u001B[0m                 \u001B[0mscore\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Private/Uni/MA/Code/dsqn_openaigym/DQN-Cartpole/agent.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, state, action, reward, next_state, done)\u001B[0m\n\u001B[1;32m    190\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmemory\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    191\u001B[0m                 \u001B[0mexperiences\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmemory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 192\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimize_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexperiences\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    193\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvisualize_actionspace\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt_step_total\u001B[0m  \u001B[0;34m%\u001B[0m \u001B[0;36m1000\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m             \u001B[0;31m# If enough samples are available in memory, get random subset and learn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Private/Uni/MA/Code/dsqn_openaigym/DQN-Cartpole/agent.py\u001B[0m in \u001B[0;36moptimize_model\u001B[0;34m(self, experiences)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0;31m# Minimize the loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 222\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    223\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 307\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    308\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    152\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 154\u001B[0;31m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[1;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/function.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mBackwardCFunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FunctionBase\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mFunctionCtx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_HookMixin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 189\u001B[0;31m     \u001B[0;32mdef\u001B[0m \u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    190\u001B[0m         \u001B[0;31m# _forward_cls is defined by derived class\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    191\u001B[0m         \u001B[0;31m# The user should define either backward or vjp but never both.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "saveHyperparameters()\n",
    "\n",
    "smoothed_scores_dsqn_all = []\n",
    "dsqn_completion_after = []\n",
    "simulation_time = 10\n",
    "scaler = init_scaler()\n",
    "\n",
    "for i_run in range(n_runs):\n",
    "    print(\"Run # {}\".format(i_run) + ' at '+getDateTime())\n",
    "    seed = seeds[i_run]\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    policy_net = DSNN(architecture, seed, alpha, beta, batch_size, threshold, simulation_time)\n",
    "    target_net = DSNN(architecture, seed, alpha, beta, batch_size, threshold, simulation_time)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    agent = Agent(env_name, policy_net, target_net, architecture, batch_size,\n",
    "                  replay_memory_size, discount_factor, eps_start, eps_end, eps_decay,\n",
    "                  update_every, target_update_frequency, optimizer, learning_rate,\n",
    "                  num_episodes, max_steps, i_run, result_dir, seed, tau, SQN=True, quantization=False)\n",
    "\n",
    "    smoothed_scores, scores, best_average_after = agent.train_agent()\n",
    "\n",
    "    np.save(result_dir + '/scores_{}'.format(i_run), scores)\n",
    "    np.save(result_dir + '/smoothed_scores_DSQN_{}'.format(i_run), smoothed_scores)\n",
    "    plot_score(smoothed_scores,i_run)\n",
    "\n",
    "    # save smoothed scores in list to plot later\n",
    "    smoothed_scores_dsqn_all.append(smoothed_scores)\n",
    "    dsqn_completion_after.append(best_average_after)\n",
    "    print(\"\")\n",
    "print(\"Finished at \"+ getDateTime())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DSQN Plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC1O1i_TY7na",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "DSQNs with two-neurons-input encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gridsearch Approach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "architecture = [4, 64, 64, 2]\n",
    "possible_threshold_boundaries = [0.3,0.3]\n",
    "possible_alpha_boundaries = [0.1, 0.1]\n",
    "possible_beta_boundaries = [0.8, 0.8]\n",
    "\n",
    "parameter_permutations = []\n",
    "granularity = 20\n",
    "\n",
    "possible_alphas = np.linspace(possible_alpha_boundaries[0],possible_alpha_boundaries[1],int(granularity/4))\n",
    "possible_betas = np.linspace(possible_beta_boundaries[0],possible_beta_boundaries[1],int(granularity/4))\n",
    "possible_thresholds = np.linspace(possible_threshold_boundaries[0],possible_threshold_boundaries[1],granularity)\n",
    "\n",
    "for a in possible_alphas:\n",
    "    for b in possible_betas:\n",
    "        for t in possible_thresholds:\n",
    "            parameter_permutations.append([a,b,t])\n",
    "\n",
    "scaler = init_scaler(two_neuron)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def create3DPlot(permutations, current_alpha, train_res, use_alphas=False):\n",
    "\n",
    "    tmp_split = np.array(permutations.get(str(current_alpha)), dtype=object).reshape(-1,2)\n",
    "\n",
    "    results_for_alpha = tmp_split[:,1]\n",
    "\n",
    "    #permuts_for_alpha = np.array(np.array(tmp_split[:,0]).tolist())\n",
    "    #betas = permuts_for_alpha[:,0]\n",
    "    #thresholds = permuts_for_alpha[:,1]\n",
    "\n",
    "    #threshold dimensions\n",
    "    dim2 = len(possible_thresholds)\n",
    "\n",
    "    dim1 = len(possible_betas)\n",
    "\n",
    "    max_number_values = dim1*dim2\n",
    "\n",
    "    def empty_grid():\n",
    "        coord_pairs = []\n",
    "        for b in possible_betas:\n",
    "            for t in possible_thresholds:\n",
    "                coord_pairs.append([b,t])\n",
    "        return np.array(coord_pairs)\n",
    "\n",
    "    empty = empty_grid()\n",
    "    X = empty[:,0].reshape((dim1,dim2))\n",
    "    Y = empty[:,1].reshape((dim1,dim2))\n",
    "\n",
    "    new_train_res = np.hstack((results_for_alpha,[-1]*(max_number_values - len(results_for_alpha))))\n",
    "    #Z = np.reshape(np.ma.array(new_train_res, mask=([0]*(len(train_res))+[1]*(len(new_train_res)-len(train_res)))), (dim1,dim2))\n",
    "    Z = new_train_res.reshape((dim1,dim2))\n",
    "\n",
    "    # Plot the surface.\n",
    "    plt.clf()\n",
    "    plt.ioff()\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                         linewidth=0, antialiased=False)\n",
    "\n",
    "    # Customize the z axis.\n",
    "    ax.set_xlim( np.min(possible_betas), np.max(possible_betas))\n",
    "    ax.set_ylim( np.min(possible_thresholds), np.max(possible_thresholds))\n",
    "    ax.set_zlim( -1, 205)\n",
    "    #ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "\n",
    "    ax.set_xlabel('Beta')\n",
    "    ax.set_ylabel('Threshold')\n",
    "    ax.set_zlabel('#Steps')\n",
    "    plt.rcParams['axes.grid'] = False\n",
    "    plt.figtext(0.5, 0.01, f'Plot for alpha {current_alpha}', ha=\"center\")\n",
    "\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "    plt.savefig(result_dir + f'/3D_plot_a{current_alpha}.png', dpi=1000)\n",
    "    plt.close(fig)\n",
    "\n",
    "#create3DPlot(set_permutations, alpha, res_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import model\n",
    "importlib.reload(model)\n",
    "from model import QNetwork, DSNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run # 0 at 02/07/2022 17:59:34\n",
      "Episode 100\tAverage Score: 14.29\t Epsilon: 0.24\n",
      "Episode 200\tAverage Score: 10.99\t Epsilon: 0.08\n",
      "Episode 300\tAverage Score: 14.54\t Epsilon: 0.05\n",
      "Episode 400\tAverage Score: 16.79\t Epsilon: 0.05\n",
      "Episode 451\tAverage Score: 15.22\t Epsilon: 0.05\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_2294487/655120111.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     35\u001B[0m                   num_episodes, max_steps, i_run, result_dir, seed, tau, SQN=True, quantization=False)\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 37\u001B[0;31m     \u001B[0msmoothed_scores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbest_average_after\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbest_average\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_agent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     38\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m     \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult_dir\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'/scores_{}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi_run\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Private/Uni/MA/Code/dsqn_openaigym/DQN-Cartpole/agent.py\u001B[0m in \u001B[0;36mtrain_agent\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    280\u001B[0m                 \u001B[0maction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect_action\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m                 \u001B[0mnext_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 282\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnext_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    283\u001B[0m                 \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    284\u001B[0m                 \u001B[0mscore\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Private/Uni/MA/Code/dsqn_openaigym/DQN-Cartpole/agent.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, state, action, reward, next_state, done, loss_hist)\u001B[0m\n\u001B[1;32m    195\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmemory\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    196\u001B[0m                 \u001B[0mexperiences\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmemory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 197\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimize_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexperiences\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_hist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    198\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    199\u001B[0m         \u001B[0;31m# For training purposes, create sample of reasonable environment states\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Private/Uni/MA/Code/dsqn_openaigym/DQN-Cartpole/agent.py\u001B[0m in \u001B[0;36moptimize_model\u001B[0;34m(self, experiences, loss_hist)\u001B[0m\n\u001B[1;32m    210\u001B[0m         \u001B[0;31m# Get max predicted Q values (for next states) from target model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSQN\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 212\u001B[0;31m             \u001B[0mQ_targets_next\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_net\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    213\u001B[0m                 \u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m                 \u001B[0;31m# gather(1, actions)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Private/Uni/MA/Code/dsqn_openaigym/DQN-Cartpole/model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, inputs, loihi)\u001B[0m\n\u001B[1;32m    190\u001B[0m                         \u001B[0mh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ab,bc->ac\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    191\u001B[0m                     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 192\u001B[0;31m                         \u001B[0mh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ab,bc->ac\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mspk_rec\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0ml\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    193\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m                 \u001B[0;31m# calculate the new synapse potential\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Private/Uni/MA/Code/dsqn_openaigym/DQN-Cartpole/DSQNvenv/lib/python3.8/site-packages/torch/functional.py\u001B[0m in \u001B[0;36meinsum\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    323\u001B[0m         \u001B[0;31m# recurse incase operands contains value that has torch function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    324\u001B[0m         \u001B[0;31m# in the original implementation this line is omitted\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 325\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mequation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0m_operands\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    326\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    327\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0m_VF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mequation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moperands\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[attr-defined]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Private/Uni/MA/Code/dsqn_openaigym/DQN-Cartpole/DSQNvenv/lib/python3.8/site-packages/torch/functional.py\u001B[0m in \u001B[0;36meinsum\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    325\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mequation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0m_operands\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    326\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 327\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_VF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mequation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moperands\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[attr-defined]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    328\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "smoothed_scores_dsqn_all = []\n",
    "dsqn_completion_after = []\n",
    "\n",
    "res_list= []\n",
    "set_permutations = {}\n",
    "\n",
    "start_index = 0\n",
    "\n",
    "\n",
    "for i_run, cur_permutation in enumerate(parameter_permutations[start_index:]):\n",
    "    print(\"Run # {}\".format(i_run) + ' at '+getDateTime())\n",
    "    seed = seeds[i_run%n_runs]\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # current hyperparameters\n",
    "    alpha = cur_permutation[0]\n",
    "    beta = cur_permutation[1]\n",
    "    threshold = cur_permutation[2]\n",
    "    params = create_params_dict()\n",
    "\n",
    "    #policy_net = DSNN(architecture, seed, alpha, beta, batch_size, threshold, simulation_time, scaler, two_neuron=two_neuron , population_coding=population_coding, population_size=population_size )\n",
    "    #target_net = DSNN(architecture, seed, alpha, beta, batch_size, threshold, simulation_time, scaler, two_neuron=two_neuron , population_coding=population_coding, population_size=population_size )\n",
    "\n",
    "    policy_net = DSNN(architecture, seed, alpha, beta, batch_size, threshold, simulation_time,  scaler=None, two_neuron=two_neuron , population_coding=population_coding, population_size=population_size, add_bias = False, encoding=experiment_type[type_nr], decoding=\"potential\")\n",
    "    target_net = DSNN(architecture, seed, alpha, beta, batch_size, threshold, simulation_time, scaler=None, two_neuron=two_neuron , population_coding=population_coding, population_size=population_size, add_bias = False, encoding=experiment_type[type_nr], decoding=\"potential\")\n",
    "\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    agent = Agent(env_name, policy_net, target_net, architecture, batch_size,\n",
    "                  replay_memory_size, discount_factor, eps_start, eps_end, eps_decay,\n",
    "                  update_every, target_update_frequency, optimizer, learning_rate,\n",
    "                  num_episodes, max_steps, i_run, result_dir, seed, tau, SQN=True, quantization=False)\n",
    "\n",
    "    smoothed_scores, scores, best_average_after, best_average = agent.train_agent()\n",
    "\n",
    "    np.save(result_dir + '/scores_{}'.format(i_run), scores)\n",
    "    np.save(result_dir + '/smoothed_scores_DSQN_{}'.format(i_run), smoothed_scores)\n",
    "\n",
    "    plot_score(smoothed_scores,i_run, params)\n",
    "\n",
    "    # save smoothed scores in list to plot later\n",
    "    smoothed_scores_dsqn_all.append(smoothed_scores)\n",
    "    dsqn_completion_after.append(best_average_after)\n",
    "\n",
    "    res_list.append(best_average)\n",
    "\n",
    "    np.savez(result_dir + '/best_res', res_list, parameter_permutations)\n",
    "\n",
    "    set_permutations.setdefault(str(alpha), ([])).append([cur_permutation[1:3], best_average])\n",
    "\n",
    "    create3DPlot(set_permutations, alpha, res_list)\n",
    "\n",
    "    print(\"\")\n",
    "print(\"Finished at \"+ getDateTime())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
<<<<<<< HEAD
=======
     "is_executing": true,
>>>>>>> local_updates
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "saveHyperparametersToFile()\n",
    "\n",
    "smoothed_scores_dsqn_all = []\n",
    "dsqn_completion_after = []\n",
    "simulation_time = 10\n",
    "scaler = init_scaler()\n",
    "\n",
    "for i_run in range(n_runs):\n",
    "    print(\"Run # {}\".format(i_run) + ' at '+ getDateTime())\n",
    "    seed = seeds[i_run]\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    policy_net = DSNN(architecture, seed, alpha, beta, 1, threshold, simulation_time, scaler)\n",
    "    target_net = DSNN(architecture, seed, alpha, beta, 1, threshold, simulation_time, scaler)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    agent = Agent(env_name, policy_net, target_net, architecture, batch_size,\n",
    "                  replay_memory_size, discount_factor, eps_start, eps_end, eps_decay,\n",
    "                  update_every, target_update_frequency, optimizer, learning_rate,\n",
    "                  num_episodes, max_steps, i_run, result_dir, seed, tau, SQN=True, quantization=False)\n",
    "\n",
    "    smoothed_scores, scores, best_average_after = agent.train_agent()\n",
    "\n",
    "    np.save(result_dir + '/scores_{}'.format(i_run), scores)\n",
    "    np.save(result_dir + '/smoothed_scores_DSQN_{}'.format(i_run), smoothed_scores)\n",
    "    plot_score(smoothed_scores,i_run)\n",
    "\n",
    "    # save smoothed scores in list to plot later\n",
    "    smoothed_scores_dsqn_all.append(smoothed_scores)\n",
    "    dsqn_completion_after.append(best_average_after)\n",
    "    print(\"\")\n",
    "print(\"Finished at \"+ getDateTime())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "metadata": {
    "id": "BzJSRspXhkOz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "## DSQN Plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "i4TQubGBbTzK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "result_dir = \"/content/drive/My Drive/Uni/MasterArbeit/dsqn_examples/results/result_20_default_2021113\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "DktjML1ahRhD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "smoothed_scores_dsqn_all = loadScores(result_dir,\"smoothed_scores_DSQN\",5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s-Zd_Oc0gn-f",
    "outputId": "f6c17dd1-a446-4b7e-a040-fc81d1a57f48",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Plot scores of individual runs\n",
    "for i in range(len(smoothed_scores_dsqn_all)):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(smoothed_scores_dsqn_all[i])\n",
    "    plt.ylim(0, 250)\n",
    "    plt.grid(True)\n",
    "    #plt.savefig(result_dir + '/training_dsqn_{}.png'.format(i), dpi=1000)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "9WwrzTCoh0bM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "best_runs = [ i for i in range(29)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(smoothed_scores_dsqn_all)"
   ],
   "metadata": {
<<<<<<< HEAD
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
=======
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "rngOZcijh4bM",
    "outputId": "826b88e9-ff64-421a-bd9e-8aae7d7c7540",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "best_smoothed_scores_dsqn = [[]]*len(smoothed_scores_dsqn_all)\n",
    "for i in range(len(smoothed_scores_dsqn_all)):\n",
    "    best_smoothed_scores_dsqn[i] = smoothed_scores_dsqn_all[best_runs[i]]\n",
    "\n",
    "mean_smoothed_scores_dsqn = np.mean(best_smoothed_scores_dsqn, axis=0)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(range(len(best_smoothed_scores_dsqn[0])), mean_smoothed_scores_dsqn)\n",
    "plt.fill_between(range(len(best_smoothed_scores_dsqn[0])),\n",
    "                 np.nanpercentile(best_smoothed_scores_dsqn, 2, axis=0),\n",
    "                 np.nanpercentile(best_smoothed_scores_dsqn, 97, axis=0), alpha=0.25)\n",
    "\n",
    "try: # in case the notebook expires, the dsqn_completions cannot be reloaed\n",
    "    if(dsqn_completion_after):\n",
    "      avg_dsqn_completion_after = [[]]*len(dsqn_completion_after)\n",
    "      for i in range(len(dsqn_completion_after)):\n",
    "          avg_dsqn_completion_after[i] = dsqn_completion_after[best_runs[i]]\n",
    "      avg_dsqn_completion_after = np.mean(avg_dsqn_completion_after)\n",
    "      plt.vlines(avg_dsqn_completion_after, 0, 250, 'C0')\n",
    "except NameError:\n",
    "    dsqn_completion_after = None\n",
    "\n",
    "\n",
    "plt.ylim(0, 250)\n",
    "plt.grid(True)\n",
    "plt.savefig(result_dir + '/DSQN_training.png', dpi=1000)\n",
    "plt.title('CartPole-v0 DSQN')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "metadata": {
    "id": "9m4PEscghHug",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Quantized DSQN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "metadata": {
    "id": "uHRj7pVIY7nb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "## Quantized DSQN Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "dMN0hu8wY7nb",
    "scrolled": false,
    "outputId": "04a51dd1-c142-47f4-b740-a5821d874ed3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "smoothed_scores_dsqn_quantized_all = []\n",
    "dsqn_quantized_completion_after = []\n",
    "simulation_time = 8\n",
    "\n",
    "for i_run in range(n_runs):\n",
    "    print(\"Run # {}\".format(i_run))\n",
    "    seed = seeds[i_run]\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    policy_net = DSQN(architecture, seed, alpha, beta, weight_scale, batch_size, threshold, simulation_time)\n",
    "    target_net = DSQN(architecture, seed, alpha, beta, weight_scale, batch_size, threshold, simulation_time)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    agent = Agent(env_name, policy_net, target_net, architecture, batch_size,\n",
    "                  replay_memory_size, discount_factor, eps_start, eps_end, eps_decay,\n",
    "                  update_every, target_update_frequency, optimizer, learning_rate,\n",
    "                  num_episodes, max_steps, i_run, result_dir, seed, tau, SQN=True, two_neurons=False,\n",
    "                  quantization=True)\n",
    "\n",
    "    smoothed_scores, scores, best_average_after = agent.train_agent()\n",
    "\n",
    "    np.save(result_dir + '/scores_{}'.format(i_run), scores)\n",
    "    np.save(result_dir + '/smoothed_scores_DSQN_Loihi_{}'.format(i_run), smoothed_scores)\n",
    "\n",
    "    # save smoothed scores in list to plot later\n",
    "    smoothed_scores_dsqn_quantized_all.append(smoothed_scores)\n",
    "    dsqn_quantized_completion_after.append(best_average_after)\n",
    "    print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "_MOaZnaUY7nc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "smoothed_scores_dsqn_quantized_all = smoothed_scores_dsqn_all\n",
    "dsqn_quantized_completion_after = dsqn_completion_after"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "OYrcBwfjY7nc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "policy_net = DSQN(architecture, seed, alpha, beta, weight_scale, batch_size, threshold, simulation_time, two_neurons=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "odWNKU81Y7nd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "dsqn_completion_after"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "HSg10m_YY7nd",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "policy_net.weights = weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "_IIPFbHCY7nd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "seed = seeds[0]\n",
    "policy_net = DSQN(architecture, seed, alpha, beta, weight_scale, batch_size, threshold, simulation_time, two_neurons=False)\n",
    "target_net = DSQN(architecture, seed, alpha, beta, weight_scale, batch_size, threshold, simulation_time, two_neurons=False)\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "agent = Agent(env_name, policy_net, target_net, architecture, batch_size,\n",
    "                  replay_memory_size, discount_factor, eps_start, eps_end, eps_decay,\n",
    "                  update_every, target_update_frequency, optimizer, learning_rate,\n",
    "                  num_episodes, max_steps, 0, result_dir, seed, tau, SQN=True, two_neurons=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "3RV4lI5pY7ne",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "weights = policy_net.weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "BttjUxoLY7ne",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "Mc6WMFzVY7ne",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "q_weights = agent.quantize_weights(weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "0mJ3HwqwY7ne",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "q_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "UgFYgZNkY7nf",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "quant_weights = [q_w.tensor.float() for q_w in q_weights]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "tZhhNwDTY7nf",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "quant_weights[0].requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "W1OPXDndY7nf",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "quant_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "-DsQm9c5Y7nf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "step = (1.8 + 1.8)/255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "Vu8HOZYuY7nf",
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "w = np.concatenate((weights[0].detach().numpy()[0], weights[0].detach().numpy()[1], weights[0].detach().numpy()[2], weights[0].detach().numpy()[3]))\n",
    "bins = np.arange(-1.8, 1.8, step)\n",
    "plt.hist(w, bins)\n",
    "plt.title('FP32 Weights')\n",
    "plt.savefig('weights_fp32.png', dpi=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "KIcdUQukY7ng",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "w = np.concatenate((quant_weights[0].detach().numpy()[0], quant_weights[0].detach().numpy()[1], quant_weights[0].detach().numpy()[2], quant_weights[0].detach().numpy()[3]), axis=0)\n",
    "bins = range(-128, 127)\n",
    "plt.hist(w, bins)\n",
    "plt.title('Quantized Weights')\n",
    "plt.savefig('weights_quantized.png', dpi=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "Z2cqLs-YY7ng",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "policy_net.weights = quant_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "cAg6y6qaY7ng",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "env = gym.make(env_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "nQxukft8Y7ng",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "obs = env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "metadata": {
    "id": "IvqltimhY7nh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "## Plot Quantized DSQN Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "dreBiOACY7nh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "smoothed_scores_dsqn_quantized_0 = np.load('result_23_2021416/smoothed_scores_DSQN_0.npy')\n",
    "smoothed_scores_dsqn_quantized_1 = np.load('result_23_2021416/smoothed_scores_DSQN_1.npy')\n",
    "smoothed_scores_dsqn_quantized_2 = np.load('result_23_2021416/smoothed_scores_DSQN_2.npy')\n",
    "smoothed_scores_dsqn_quantized_3 = np.load('result_23_2021416/smoothed_scores_DSQN_3.npy')\n",
    "smoothed_scores_dsqn_quantized_4 = np.load('result_23_2021416/smoothed_scores_DSQN_4.npy')\n",
    "smoothed_scores_dsqn_quantized_5 = np.load('result_23_2021416/smoothed_scores_DSQN_5.npy')\n",
    "smoothed_scores_dsqn_quantized_6 = np.load('result_23_2021416/smoothed_scores_DSQN_6.npy')\n",
    "smoothed_scores_dsqn_quantized_7 = np.load('result_23_2021416/smoothed_scores_DSQN_7.npy')\n",
    "smoothed_scores_dsqn_quantized_8 = np.load('result_23_2021416/smoothed_scores_DSQN_8.npy')\n",
    "smoothed_scores_dsqn_quantized_9 = np.load('result_23_2021416/smoothed_scores_DSQN_9.npy')\n",
    "smoothed_scores_dsqn_quantized_all = [smoothed_scores_dsqn_quantized_0, smoothed_scores_dsqn_quantized_1, smoothed_scores_dsqn_quantized_2, smoothed_scores_dsqn_quantized_3, smoothed_scores_dsqn_quantized_4, smoothed_scores_dsqn_quantized_5, smoothed_scores_dsqn_quantized_6, smoothed_scores_dsqn_quantized_7, smoothed_scores_dsqn_quantized_8, smoothed_scores_dsqn_quantized_9]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "-gcAbM1IY7ni",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "best_smoothed_scores_dsqn_quantized = [smoothed_scores_dsqn_quantized_all[best_runs[0]],\n",
    "                             smoothed_scores_dsqn_quantized_all[best_runs[1]],\n",
    "                             smoothed_scores_dsqn_quantized_all[best_runs[2]],\n",
    "                             smoothed_scores_dsqn_quantized_all[best_runs[3]],\n",
    "                             smoothed_scores_dsqn_quantized_all[best_runs[4]],\n",
    "                             smoothed_scores_dsqn_quantized_all[best_runs[5]],\n",
    "                             smoothed_scores_dsqn_quantized_all[best_runs[6]],\n",
    "                             smoothed_scores_dsqn_quantized_all[best_runs[7]],\n",
    "                             smoothed_scores_dsqn_quantized_all[best_runs[8]],\n",
    "                             smoothed_scores_dsqn_quantized_all[best_runs[9]]]\n",
    "mean_smoothed_scores_dsqn_quantized = np.mean(best_smoothed_scores_dsqn_quantized, axis=0)\n",
    "\n",
    "avg_dsqn_quantized_completion_after = np.mean([dsqn_quantized_completion_after[best_runs[0]],\n",
    "                                dsqn_quantized_completion_after[best_runs[1]],\n",
    "                                dsqn_quantized_completion_after[best_runs[2]],\n",
    "                                dsqn_quantized_completion_after[best_runs[3]],\n",
    "                                dsqn_quantized_completion_after[best_runs[4]],\n",
    "                                dsqn_quantized_completion_after[best_runs[5]],\n",
    "                                dsqn_quantized_completion_after[best_runs[6]],\n",
    "                                dsqn_quantized_completion_after[best_runs[7]],\n",
    "                                dsqn_quantized_completion_after[best_runs[8]],\n",
    "                                dsqn_quantized_completion_after[best_runs[9]]])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(range(len(best_smoothed_scores_dsqn_quantized[0])), mean_smoothed_scores_dsqn_quantized)\n",
    "plt.fill_between(range(len(best_smoothed_scores_dsqn_quantized[0])),\n",
    "                 np.nanpercentile(best_smoothed_scores_dsqn_quantized, 2, axis=0),\n",
    "                 np.nanpercentile(best_smoothed_scores_dsqn_quantized, 97, axis=0), alpha=0.25)\n",
    "\n",
    "plt.vlines(avg_dsqn_quantized_completion_after, 0, 250, 'C0')\n",
    "\n",
    "\n",
    "plt.ylim(0, 250)\n",
    "plt.grid(True)\n",
    "plt.savefig(result_dir + '/DSQN_training.png', dpi=1000)\n",
    "plt.title('CartPole-v0 DSQN Quantized')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "XWpl29SIY7ni",
    "scrolled": false,
    "outputId": "b1f59377-30f4-41f4-e141-7853fdb62be1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Plot smoothed DQN vs. DSQN Training\n",
    "#mean_smoothed_scores_dqn = np.mean(smoothed_scores_dqn_all, axis=0)\n",
    "#mean_smoothed_scores_dsqn = np.mean(smoothed_scores_dsqn_all, axis=0)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "dqn = plt.plot(range(len(best_smoothed_scores_dqn[0])), mean_smoothed_scores_dqn, color='C0', label='DQN')\n",
    "plt.fill_between(range(len(best_smoothed_scores_dqn[0])),\n",
    "                 np.nanpercentile(best_smoothed_scores_dqn, 2, axis=0),\n",
    "                 np.nanpercentile(best_smoothed_scores_dqn, 97, axis=0), alpha=0.25)\n",
    "plt.vlines(avg_dqn_completion_after, 0, 250, 'C0')\n",
    "\n",
    "dsqn = plt.plot(range(len(best_smoothed_scores_dsqn[0])), mean_smoothed_scores_dsqn, color='C1', label='DSQN')\n",
    "plt.fill_between(range(len(best_smoothed_scores_dsqn[0])),\n",
    "                 np.nanpercentile(best_smoothed_scores_dsqn, 2, axis=0),\n",
    "                 np.nanpercentile(best_smoothed_scores_dsqn, 97, axis=0), alpha=0.25)\n",
    "plt.vlines(avg_dsqn_completion_after, 0, 250, 'C1')\n",
    "\n",
    "#dsqn_quantized = plt.plot(range(len(best_smoothed_scores_dsqn_quantized[0])), mean_smoothed_scores_dsqn_quantized, color='C2', label='Quantized DSQN')\n",
    "#plt.fill_between(range(len(best_smoothed_scores_dsqn_quantized[0])),\n",
    "#                 np.nanpercentile(best_smoothed_scores_dsqn_quantized, 2, axis=0),\n",
    "#                 np.nanpercentile(best_smoothed_scores_dsqn_quantized, 97, axis=0), alpha=0.25)\n",
    "#plt.vlines(avg_dsqn_quantized_completion_after, 0, 250, 'C2')\n",
    "\n",
    "\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 250)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('episode')\n",
    "plt.ylabel('sum of rewards')\n",
    "plt.title(env_name)\n",
    "plt.savefig(result_dir + '/DQN_vs_DSQN_training.png', dpi=1000)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "metadata": {
    "id": "fT8o7oXAY7ni",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "## Evaluate trained DQN and DSQN models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "FIl7YkpGY7nj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "gym_evaluation_seeds = [random.getrandbits(32) for _ in range(n_evaluations)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "0jeP7lf0jswp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "import importlib\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "U0HmmggPpH-g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "import agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbtB2mhGoMXp",
    "outputId": "d22124be-80ca-4051-f6e6-5f2e40caaed6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "importlib.reload(agent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "tDY7NpNdsEHd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "from agent import Agent, ReplayBuffer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "UFV8nGxZjZF6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "test_agent = Agent(env_name, policy_net, target_net, architecture, batch_size,\n",
    "                  replay_memory_size, discount_factor, eps_start, eps_end, eps_decay,\n",
    "                  update_every, target_update_frequency, optimizer, learning_rate,\n",
    "                  num_episodes, max_steps, i_run, result_dir, seed, tau, SQN=True, quantization=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c45dMhVWY7nj",
    "scrolled": false,
    "outputId": "3ec6b4e7-5228-46ba-8c2c-b502159ace6c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Test best trained DQN on the same environment for 200 timesteps\n",
    "evaluation_dqn_200 = []\n",
    "for i in best_runs:\n",
    "    print(\"Run # {}\".format(i))\n",
    "    dqn = QNetwork(architecture, 1).to(device)\n",
    "    dqn.load_state_dict(torch.load(result_dir + '/checkpoint_DQN_{}.pt'.format(i)))\n",
    "    rewards = test_agent.evaluate_agent(dqn, env, 100, 200, gym_evaluation_seeds, quantization=False)\n",
    "    evaluation_dqn_200.extend(rewards)\n",
    "    print(\"Mean Rewards: {}\".format(np.mean(rewards)))\n",
    "    print(\"Deviation: {}\".format(np.std(rewards)))\n",
    "    print(\"-----------------\")\n",
    "np.save(result_dir + '/evaluation_dqn_200', evaluation_dqn_200)\n",
    "print(\"Total Mean Reward: {}\".format(np.mean(evaluation_dqn_200)))\n",
    "print(\"Total Deviation: {}\".format(np.std(evaluation_dqn_200)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43_9BW4rY7nk",
    "outputId": "7ba67ecc-34cb-4d66-869a-7f528fee1711",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Test best trained DQN on the same environment for 500 timesteps\n",
    "evaluation_dqn_500 = []\n",
    "for i in best_runs:\n",
    "    print(\"Run # {}\".format(i))\n",
    "    dqn = QNetwork(architecture, 1).to(device)\n",
    "    dqn.load_state_dict(torch.load(result_dir + '/checkpoint_DQN_{}.pt'.format(i)))\n",
    "    rewards = test_agent.evaluate_agent(dqn, env, 100, 500, gym_evaluation_seeds, quantization=False)\n",
    "    evaluation_dqn_500.extend(rewards)\n",
    "    print(\"Mean Rewards: {}\".format(np.mean(rewards)))\n",
    "    print(\"Deviation: {}\".format(np.std(rewards)))\n",
    "    print(\"-----------------\")\n",
    "np.save(result_dir + '/evaluation_dqn_500', evaluation_dqn_500)\n",
    "print(\"Total Mean Reward: {}\".format(np.mean(evaluation_dqn_500)))\n",
    "print(\"Total Deviation: {}\".format(np.std(evaluation_dqn_500)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QvnSqQaDY7nk",
    "outputId": "8684ae8d-072b-4ee8-fd14-b56cf453955f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Test best trained DQN on the same environment for 1000 timesteps\n",
    "evaluation_dqn_1000 = []\n",
    "for i in best_runs:\n",
    "    print(\"Run # {}\".format(i))\n",
    "    dqn = QNetwork(architecture, 1).to(device)\n",
    "    dqn.load_state_dict(torch.load(result_dir + '/checkpoint_DQN_{}.pt'.format(i)))\n",
    "    rewards = test_agent.evaluate_agent(dqn, env, 100, 1000, gym_evaluation_seeds, quantization=False)\n",
    "    evaluation_dqn_1000.extend(rewards)\n",
    "    print(\"Mean Rewards: {}\".format(np.mean(rewards)))\n",
    "    print(\"Deviation: {}\".format(np.std(rewards)))\n",
    "    print(\"-----------------\")\n",
    "np.save(result_dir + '/evaluation_dqn_1000', evaluation_dqn_1000)\n",
    "print(\"Total Mean Reward: {}\".format(np.mean(evaluation_dqn_1000)))\n",
    "print(\"Total Deviation: {}\".format(np.std(evaluation_dqn_1000)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "iyYZHudFY7nk",
    "outputId": "94271157-dc11-4569-9d8d-02c6210ae43d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Test best trained DSQN on the same environment for 200 timesteps\n",
    "evaluation_dsqn_200 = []\n",
    "for i in best_runs:\n",
    "    print(\"Run # {}\".format(i))\n",
    "    dsqn = DSQN(architecture, 0, alpha, beta, weight_scale, 1, threshold, simulation_time)\n",
    "    dsqn.load_state_dict(torch.load(result_dir + '/checkpoint_DSQN_{}.pt'.format(i)))\n",
    "    rewards = agent.evaluate_agent(dsqn, env, 100, 200, gym_evaluation_seeds, quantization=False)\n",
    "    evaluation_dsqn_200.extend(rewards)\n",
    "    print(\"Mean Rewards: {}\".format(np.mean(rewards)))\n",
    "    print(\"Deviation: {}\".format(np.std(rewards)))\n",
    "    print(\"-----------------\")\n",
    "np.save(result_dir + '/evaluation_dsqn_200', evaluation_dsqn_200)\n",
    "print(\"Total Mean Reward: {}\".format(np.mean(evaluation_dsqn_200)))\n",
    "print(\"Total Deviation: {}\".format(np.std(evaluation_dsqn_200)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "G6kGRlmtY7nk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Test best trained DSQN on the same environment for 200 timesteps\n",
    "evaluation_dsqn_500 = []\n",
    "for i in best_runs:\n",
    "    print(\"Run # {}\".format(i))\n",
    "    dsqn = DSQN(architecture, 0, alpha, beta, weight_scale, 1, threshold, simulation_time)\n",
    "    dsqn.load_state_dict(torch.load(result_dir + '/checkpoint_DSQN_{}.pt'.format(i)))\n",
    "    rewards = agent.evaluate_agent(dsqn, 100, 500, gym_evaluation_seeds)\n",
    "    evaluation_dsqn_500.extend(rewards)\n",
    "    print(\"Mean Rewards: {}\".format(np.mean(rewards)))\n",
    "    print(\"Deviation: {}\".format(np.std(rewards)))\n",
    "    print(\"-----------------\")\n",
    "np.save(result_dir + '/evaluation_dsqn_500', evaluation_dsqn_500)\n",
    "print(\"Total Mean Reward: {}\".format(np.mean(evaluation_dsqn_500)))\n",
    "print(\"Total Deviation: {}\".format(np.std(evaluation_dsqn_500)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "5KJgxGBsY7nl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Test best trained DSQN on the same environment for 200 timesteps\n",
    "evaluation_dsqn_1000 = []\n",
    "for i in best_runs:\n",
    "    print(\"Run # {}\".format(i))\n",
    "    dsqn = DSQN(architecture, 0, alpha, beta, weight_scale, 1, threshold, simulation_time)\n",
    "    dsqn.load_state_dict(torch.load(result_dir + '/checkpoint_DSQN_{}.pt'.format(i)))\n",
    "    rewards = agent.evaluate_agent(dsqn, 100, 1000, gym_evaluation_seeds)\n",
    "    evaluation_dsqn_1000.extend(rewards)\n",
    "    print(\"Mean Rewards: {}\".format(np.mean(rewards)))\n",
    "    print(\"Deviation: {}\".format(np.std(rewards)))\n",
    "    print(\"-----------------\")\n",
    "np.save(result_dir + '/evaluation_dsqn_1000', evaluation_dsqn_1000)\n",
    "print(\"Total Mean Reward: {}\".format(np.mean(evaluation_dsqn_1000)))\n",
    "print(\"Total Deviation: {}\".format(np.std(evaluation_dsqn_1000)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "metadata": {
    "id": "pf_ON2_BY7nl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
>>>>>>> local_updates
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "sdevNB3vY7nl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "means = [np.mean(evaluation_dqn_200), np.mean(evaluation_dsqn_200)]\n",
    "stds = [np.std(evaluation_dqn_200), np.std(evaluation_dsqn_200)]\n",
    "#x_pos = np.arange(len(means))\n",
    "x_pos = [0.5, .65]\n",
    "\n",
    "plt.bar(x_pos, means, yerr=stds, align='center', alpha=0.5, capsize=10, width=0.1)\n",
    "plt.ylim(0, 250)\n",
    "plt.xticks(x_pos, ['DQN', 'DSQN'])\n",
    "plt.ylabel('Accumlative Reward')\n",
    "plt.title('CartPole-v0 Evaluation over 200 timesteps')\n",
    "plt.grid(True)\n",
    "plt.savefig(result_dir + '/CartPole_evaluation_200.png', dpi=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "LtAxA5rEY7nl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "means = [np.mean(evaluation_dqn_500), np.mean(evaluation_dsqn_500)]\n",
    "stds = [np.std(evaluation_dqn_500), np.std(evaluation_dsqn_500)]\n",
    "x_pos = [0.5, .65]\n",
    "\n",
    "plt.bar(x_pos, means, yerr=stds, align='center', alpha=0.5, capsize=10, width=0.1)\n",
    "plt.ylim(0, 550)\n",
    "plt.xticks(x_pos, ['DQN', 'DSQN'])\n",
    "plt.ylabel('Accumlative Reward')\n",
    "plt.title('CartPole-v0 Evaluation over 500 timesteps')\n",
    "plt.grid(True)\n",
    "plt.savefig(result_dir + '/CartPole_evaluation_500.png', dpi=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "W3PCQU-pY7nm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "means = [np.mean(evaluation_dqn_1000), np.mean(evaluation_dsqn_1000)]\n",
    "stds = [np.std(evaluation_dqn_1000), np.std(evaluation_dsqn_1000)]\n",
    "x_pos = [0.5, .65]\n",
    "\n",
    "plt.bar(x_pos, means, yerr=stds, align='center', alpha=0.5, capsize=10, width=0.1)\n",
    "plt.ylim(0, 1150)\n",
    "plt.xticks(x_pos, ['DQN', 'DSQN'])\n",
    "plt.ylabel('Accumlative Reward')\n",
    "plt.title('CartPole-v0 Evaluation over 1000 timesteps')\n",
    "plt.grid(True)\n",
    "plt.savefig(result_dir + '/CartPole_evaluation_1000.png', dpi=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "o7N24X3iY7nm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Get the membrane potential of the first layer, first item in batch\n",
    "potential = [mem[1][0] for mem in mem_rec]\n",
    "neuron1 = [p[0] for p in potential]\n",
    "neuron2 = [p[1] for p in potential]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "uvP24L4yY7nm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Plot the membrane potential for both output neurons for one random run before training\n",
    "plt.plot(neuron1, color='b', label='Output Neuron 1')\n",
    "plt.plot(neuron2, color='g', label='Output Neuron 2')\n",
    "plt.grid(True)\n",
    "plt.ylim(-25, 25)\n",
    "plt.xlabel('time steps')\n",
    "plt.ylabel('membrane potential')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('cartpole_output_neurons_potential_b4_training.png', dpi=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "IVEEIr89Y7nn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Get the membrane potential of the hidden layer neurons\n",
    "potential = [mem[0][0] for mem in mem_rec]\n",
    "neurons = []\n",
    "for i in range(len(potential[0])):\n",
    "    neurons.append([p[i] for p in potential])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "n71bkoH1Y7nn",
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Plot the membrane potential for the hidden layer neurons\n",
    "for i in range(len(neurons)):\n",
    "    plt.plot(neurons[i], label='neuron {}'.format(i + 1))\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('membrane potential')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "metadata": {
    "id": "ctzzw6EnY7nn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "Test Code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "outputs": [],
=======
   "metadata": {
    "id": "rZJK_0h6Y7nn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
>>>>>>> local_updates
   "source": [
    "# Fill the play buffer with some data\n",
    "env = gym.make(env_name)\n",
    "memory = ReplayBuffer(replay_memory_size, batch_size, random_seeds[0])\n",
    "for i in range(1000):\n",
    "    print(\"Episode: {}\".format(i), end='\\r')\n",
    "    state = env.reset()\n",
    "    for t in range(1000):\n",
    "    for t in range(1000):\n",
    "        action = random.randint(0, 1)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        memory.add(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n"
   ],
   "metadata": {
<<<<<<< HEAD
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
=======
    "id": "beMrVpyWY7no",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import sunblaze_envs"
   ],
   "execution_count": null,
   "outputs": []
>>>>>>> local_updates
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qZTQhl8vY7no",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "random_env = sunblaze_envs.make('SunblazeCartPoleRandomNormal-v0')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wybf3NogY7no",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "result_dir = 'result_20_2021122'\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K-zaUTN8Y7no",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "evaluation_dsqn_random_200 = []\n",
    "\n",
    "dsqn = DSQN(architecture, 0, alpha, beta, weight_scale, 1, threshold, simulation_time)\n",
    "optimizer = optim.Adam(dsqn.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in best_runs:\n",
    "    print(\"Run # {}\".format(i))\n",
    "    dsqn = DSQN(architecture, 0, alpha, beta, weight_scale, 1, threshold, simulation_time)\n",
    "    dsqn.load_state_dict(torch.load(result_dir + '/checkpoint_DSQN_{}.pt'.format(i)))\n",
    "    \n",
    "    agent = Agent(env_name, dsqn, dsqn, architecture, batch_size,\n",
    "              replay_memory_size, discount_factor, eps_start, eps_end, eps_decay,\n",
    "              update_every, target_update_frequency, optimizer, learning_rate,\n",
    "              num_episodes, max_steps, 0, result_dir, 0, tau, SQN=True, two_neurons=False, random=True)\n",
    "    \n",
    "    rewards = agent.evaluate_agent(dsqn, 100, 200, gym_evaluation_seeds)\n",
    "    evaluation_dsqn_random_200.extend(rewards)\n",
    "    print(\"Mean Rewards: {}\".format(np.mean(rewards)))\n",
    "    print(\"Deviation: {}\".format(np.std(rewards)))\n",
    "    print(\"-----------------\")\n",
    "np.save(result_dir + '/evaluation_dsqn_200', evaluation_dsqn_random_200)\n",
    "print(\"Total Mean Reward: {}\".format(np.mean(evaluation_dsqn_random_200)))\n",
    "print(\"Total Deviation: {}\".format(np.std(evaluation_dsqn_random_200)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oPzLzY9IY7np",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "evaluation_dqn_random_200 = []\n",
    "\n",
    "for i in best_runs:\n",
    "    print(\"Run # {}\".format(i))\n",
    "    dqn = QNetwork(architecture, 1).to(device)\n",
    "    dqn.load_state_dict(torch.load(result_dir + '/checkpoint_DQN_{}.pt'.format(i)))\n",
    "    rewards = agent.evaluate_agent(dqn, 100, 200, gym_evaluation_seeds)\n",
    "    evaluation_dqn_random_200.extend(rewards)\n",
    "    print(\"Mean Rewards: {}\".format(np.mean(rewards)))\n",
    "    print(\"Deviation: {}\".format(np.std(rewards)))\n",
    "    print(\"-----------------\")\n",
    "np.save(result_dir + '/evaluation_dqn_200', evaluation_dqn_random_200)\n",
    "print(\"Total Mean Reward: {}\".format(np.mean(evaluation_dqn_random_200)))\n",
    "print(\"Total Deviation: {}\".format(np.std(evaluation_dqn_random_200)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "klmqC7TdY7np",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "result_dir"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}